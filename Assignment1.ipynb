{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import essential libraries\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to input the textfile data\n",
    "def Read_TxtFile(file_name):\n",
    "    with open(file_name, 'r') as data:\n",
    "        word = []\n",
    "        freq = []\n",
    "        for line in data:\n",
    "            fields = line.split()\n",
    "            word.append(fields[0])\n",
    "            freq.append(int(fields[1]))\n",
    "\n",
    "    return word,freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning the textfile data into variables\n",
    "word,count=Read_TxtFile('hw1_word_counts_05.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get the 15 most frequent words\n",
    "def max_count_probability_index(n,count,word):\n",
    "    prob=count/np.sum(count)\n",
    "    max_word=[]\n",
    "    max_prob_count=[]\n",
    "    for index in np.argsort(count)[-n:]:\n",
    "        max_word.append(word[index])\n",
    "        max_prob_count.append(prob[index])\n",
    "    return max_word[::-1],max_prob_count[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_word,max_prob_count=max_count_probability_index(15,count,word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most frequent words in the word list\n",
      "word    Probability\n",
      "THREE   0.03562714868653127\n",
      "SEVEN   0.023332724928853858\n",
      "EIGHT   0.021626496097709325\n",
      "WOULD   0.02085818430793947\n",
      "ABOUT   0.020541544349751077\n",
      "THEIR   0.018974130893766185\n",
      "WHICH   0.018545160072784138\n",
      "AFTER   0.01436452108630337\n",
      "FIRST   0.014345603577470525\n",
      "FIFTY   0.013942725872119989\n",
      "OTHER   0.013836135494765265\n",
      "FORTY   0.012387837111638222\n",
      "YEARS   0.011598389898206841\n",
      "THERE   0.01128553344178502\n",
      "SIXTY   0.009535207245223231\n"
     ]
    }
   ],
   "source": [
    "print('most frequent words in the word list')\n",
    "print('word    Probability')\n",
    "for w,p in zip(max_word,max_prob_count):\n",
    "    print(w+'   '+str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get the 14 least frequent words\n",
    "def min_count_probability_index(n,count,word):\n",
    "    prob=count/np.sum(count)\n",
    "    min_word=[]\n",
    "    min_prob_count=[]\n",
    "    for index in np.argsort(count)[:n]:\n",
    "        min_word.append(word[index])\n",
    "        min_prob_count.append(prob[index])\n",
    "    return min_word,min_prob_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_word,min_prob_count=min_count_probability_index(14,count,word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "least frequent words in the word list\n",
      "word    Probability\n",
      "MAPCO   7.827934689453437e-07\n",
      "BOSAK   7.827934689453437e-07\n",
      "CAIXA   7.827934689453437e-07\n",
      "OTTIS   7.827934689453437e-07\n",
      "TROUP   7.827934689453437e-07\n",
      "CLEFT   9.13259047102901e-07\n",
      "FOAMY   9.13259047102901e-07\n",
      "CCAIR   9.13259047102901e-07\n",
      "SERNA   9.13259047102901e-07\n",
      "YALOM   9.13259047102901e-07\n",
      "TOCOR   9.13259047102901e-07\n",
      "NIAID   9.13259047102901e-07\n",
      "PAXON   9.13259047102901e-07\n",
      "FABRI   9.13259047102901e-07\n"
     ]
    }
   ],
   "source": [
    "print('least frequent words in the word list')\n",
    "print('word    Probability')\n",
    "for w,p in zip(min_word,min_prob_count):\n",
    "    print(w+'   '+str(p))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finds Lx=l given W=w (Here x=0,1,2,3,4)\n",
    "def letter_list_probability(letter,word_prob,letter_prob_list,\\\n",
    "                            letter_list,flagletter,i=0):\n",
    "    for j in range(0,len(letter_list)):\n",
    "        #if Lx=l  given Ly!=l then P(Lx=l|W=w)=1 (Here x=0,1,2,3,4)\n",
    "        if letter_list[j]==letter and letter_list[j] not in flagletter:\n",
    "            letter_prob_list[i][j]+=word_prob\n",
    "            flagletter.append(letter_list[j])\n",
    "             \n",
    "    return letter_prob_list,flagletter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nth_letter_probability(word,word_prob,position_index_list):\n",
    "    letter_list=list(string.ascii_uppercase)\n",
    "    letter_prob_list=np.zeros([5,26])\n",
    "    for w, wp in zip(word,word_prob):\n",
    "        flagletter=[]\n",
    "        for i in position_index_list:\n",
    "            letter_prob_list,flagletter=\\\n",
    "            letter_list_probability\\\n",
    "            (w[i],wp,letter_prob_list,\\\n",
    "             letter_list,flagletter,i)\n",
    "    return np.sum(letter_prob_list,0),letter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_given_E(word,IsLetterDict,NotIsLetterDict,count):\n",
    "    residual_word_list_index=[]\n",
    "    residual_word_list=[]\n",
    "    if bool(NotIsLetterDict):\n",
    "        for w in word:\n",
    "            for i in list(NotIsLetterDict.keys()):\n",
    "                if w[i] in NotIsLetterDict[i]:\n",
    "                    residual_word_list_index.append(word.index(w))\n",
    "                    residual_word_list.append(w)\n",
    "                    break\n",
    "    new_word = [x for x in word if not x in residual_word_list]\n",
    "    new_count= [z for i, z in enumerate(count)\\\n",
    "                if i not in residual_word_list_index]\n",
    "    residual_word_list=[]\n",
    "    residual_word_list_index=[]\n",
    "    if bool(IsLetterDict):\n",
    "        for w in new_word:\n",
    "            for j in list(IsLetterDict.keys()):\n",
    "                if  w[j] not in IsLetterDict[j]:\n",
    "                    residual_word_list_index.append(new_word.index(w))\n",
    "                    residual_word_list.append(w)\n",
    "                    break\n",
    "    new_word2= [x for x in new_word if not x in residual_word_list]\n",
    "    new_count2= [z for i, z in enumerate(new_count)\\\n",
    "                 if i not in residual_word_list_index]\n",
    "    return new_word2,new_count2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "IsLetterDict=[]\n",
    "NotIsLetterDict=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "IsLetterDict.append({})\n",
    "NotIsLetterDict.append({0:[],1:[],2:[],3:[],4:[]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "IsLetterDict.append({})\n",
    "NotIsLetterDict.append({0:['E','A'],1:['E','A'],\\\n",
    "                        2:['E','A'],3:['E','A'],4:['E','A']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "IsLetterDict.append({0:['A'],4:['S']})\n",
    "NotIsLetterDict.append({1:['A','S'],2:['A','S'],3:['A','S']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "IsLetterDict.append({0:['A'],4:['S']})\n",
    "NotIsLetterDict.append({1:['A','S','I'],2:['A','S','I'],3:['A','S','I']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "IsLetterDict.append({2:['O']})\n",
    "NotIsLetterDict.append({0:['A','E','O','M','N','T'],\\\n",
    "                        1:['A','E','O','M','N','T'],\\\n",
    "                        3:['A','E','O','M','N','T'],\\\n",
    "                        4:['A','E','O','M','N','T']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "IsLetterDict.append({})\n",
    "NotIsLetterDict.append({0:['E','O'],1:['E','O'],2:['E','O'],\\\n",
    "                        3:['E','O'],4:['E','O']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "IsLetterDict.append({0:'D',3:'I'})\n",
    "NotIsLetterDict.append({1:['D','I'],2:['D','I'],4:['D','I']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "IsLetterDict.append({0:'D',3:'I'})\n",
    "NotIsLetterDict.append({1:['D','A','I'],2:['D','A','I'],4:['D','A','I']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "IsLetterDict.append({1:'U'})\n",
    "NotIsLetterDict.append({0:['A','E','I','O','S','U'],\\\n",
    "                        2:['A','E','I','O','S','U'],\\\n",
    "                        3:['A','E','I','O','S','U'],\\\n",
    "                        4:['A','E','I','O','S','U']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing the final answer\n",
    "def print_answer(word,IsLetterDict,NotIsLetterDict,count):\n",
    "    new_word,new_count=word_given_E(word,IsLetterDict,\\\n",
    "                                    NotIsLetterDict,count)\n",
    "    letter_prob_list,letter_list=\\\n",
    "    nth_letter_probability(new_word,new_count/np.sum(new_count),\\\n",
    "                           list(NotIsLetterDict.keys()))\n",
    "    \n",
    "    print('Most probable letter is: '+ \\\n",
    "          letter_list[np.argmax(letter_prob_list)])\n",
    "    print('The probability of the most probable letter is: ' \\\n",
    "          + str(round(np.max(letter_prob_list),4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most probable letter is: E\n",
      "The probability of the most probable letter is: 0.5394\n",
      "Most probable letter is: O\n",
      "The probability of the most probable letter is: 0.534\n",
      "Most probable letter is: E\n",
      "The probability of the most probable letter is: 0.7715\n",
      "Most probable letter is: E\n",
      "The probability of the most probable letter is: 0.7127\n",
      "Most probable letter is: R\n",
      "The probability of the most probable letter is: 0.7454\n",
      "Most probable letter is: I\n",
      "The probability of the most probable letter is: 0.6366\n",
      "Most probable letter is: A\n",
      "The probability of the most probable letter is: 0.8207\n",
      "Most probable letter is: E\n",
      "The probability of the most probable letter is: 0.7521\n",
      "Most probable letter is: Y\n",
      "The probability of the most probable letter is: 0.627\n"
     ]
    }
   ],
   "source": [
    "for isl,nisl in zip(IsLetterDict,NotIsLetterDict):\n",
    "    print_answer(word,isl,nisl,count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
